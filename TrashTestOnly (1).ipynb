{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrashTestOnly.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"WL1KJuSvwRIM","colab_type":"code","outputId":"b19f8f59-3566-416d-a0d8-05532e20bd88","executionInfo":{"status":"ok","timestamp":1564083618406,"user_tz":300,"elapsed":213,"user":{"displayName":"Yogurt 494","photoUrl":"","userId":"00985675351945098911"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","#tf.layers.Layer\n","tf.keras.layers.Layer"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.keras.engine.base_layer.Layer"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"IG4xgdxwoTGx","colab_type":"code","colab":{}},"source":["#pip install --upgrade tensorflow"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n24U40iAt-fN","colab_type":"code","outputId":"596bdecf-2abe-427b-d141-741d11ffb07c","executionInfo":{"status":"error","timestamp":1564083619818,"user_tz":300,"elapsed":268,"user":{"displayName":"Yogurt 494","photoUrl":"","userId":"00985675351945098911"}},"colab":{"base_uri":"https://localhost:8080/","height":132}},"source":["#does not work - unneeded\n","class InceptionI3d(snt.AbstractModule):\n","  VALID_ENDPOINTS = (\n","      'Conv3d_1a_7x7',\n","      'MaxPool3d_2a_3x3',\n","      'Conv3d_2b_1x1',\n","      'Conv3d_2c_3x3',\n","      'MaxPool3d_3a_3x3',\n","      'Mixed_3b',\n","      'Mixed_3c',\n","      'MaxPool3d_4a_3x3',\n","      'Mixed_4b',\n","      'Mixed_4c',\n","      'Mixed_4d',\n","      'Mixed_4e',\n","      'Mixed_4f',\n","      'MaxPool3d_5a_2x2',\n","      'Mixed_5b',\n","      'Mixed_5c',\n","      'Logits',\n","      'Predictions',\n","  )\n","  def __init__(self, num_classes=400, spatial_squeeze=True,\n","               final_endpoint='Logits', name='inception_i3d'):\n","    if final_endpoint not in InceptionI3d.VALID_ENDPOINTS:\n","      raise ValueError('Unknown final endpoint %s' % final_endpoint)\n","    name = \n","    super(InceptionI3d, InceptionI3d).__init__(name == name)\n","    self._num_classes = num_classes\n","    self._spatial_squeeze = spatial_squeeze\n","    self._final_endpoint = final_endpoint"],"execution_count":40,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-4279501586fe>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    name =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"oCGd85Q6ZYLg","colab_type":"code","colab":{}},"source":["#DO NOT USE\n","\n","def cnn_model_fn(features, labels, mode):\n","    input_layer = tf.reshape(features[\"x\"], [-1, 60, 20, 20, 3])\n","    #Conv3d_1a_7x7\n","    conv1 = tf.layers.conv3d(\n","      inputs=input_layer,\n","      filters=32,\n","      kernel_size=[7,7,7],\n","      padding=\"same\",\n","      activation=tf.nn.relu)\n","    pool1 = tf.layers.max_pooling3d(inputs=conv1, pool_size=[2, 2, 2], strides=2, name='MaxPool3d_1')\n","    #MaxPool3d_2a_3x3\n","    conv2 = tf.layers.conv3d(\n","      inputs=pool1,\n","      filters=64,\n","      kernel_size=[1, 1, 3, 3, 1],\n","      padding=\"same\",\n","      activation=tf.nn.relu)\n","    #pool2 = tf.layers.max_pooling3d(inputs=conv2, pool_size=[2, 2, 2], strides=[1, 1, 2, 2, 1], name='MaxPool3d_2')\n","    #pool2_flat = tf.reshape(pool2, [-1, 1920000])\n","    #'Conv3d_2b_1x1'\n","    conv3 = tf.layers.conv3d(\n","      inputs = input_layer,\n","      filters = 64,\n","      kernel_size = [1, 1, 1],\n","      padding = \"same\",\n","      activation=tf.nn.relu)\n","    pool3=tf.layers.max_pooling3d(inputs=conv3, pool_size=[2, 2, 2], strides=2, name='MaxPool3d_3')\n","    #'Conv3d_2c_3x3'\n","    conv4 = tf.layers.conv3d(\n","      inputs = input_layer,\n","      filters = 192,\n","      kernel_size = [3, 3, 3],\n","      padding =\"same\",\n","     activation=tf.nn.relu)#, pool var needed?\n","    #pool5 = tf.layers.max_pooling3d(inputs=conv5, pool_size=[2, 2, 2], strides=[1, 1, 2, 2, 1], name='MaxPool3d_4')    \n","    #'MaxPool3d_3a_3x3'\n","    conv5 = tf.layers.conv3d(\n","      inputs = pool3,#number4\n","      filters = 64,\n","      kernel_size=[1, 1, 3, 3, 1],\n","      padding=\"same\",\n","      activation=tf.nn.relu)\n","    pool5 = tf.layers.max_pooling3d(inputs=conv5, pool_size=[2, 2, 2], strides=[1, 1, 2, 2, 1], name='MaxPool3d_5')        \n","    \n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uChAEYGdp9_j","colab_type":"code","outputId":"3a9a94e7-6172-46f4-8eb6-3d5839cac12e","executionInfo":{"status":"error","timestamp":1564089474099,"user_tz":300,"elapsed":332,"user":{"displayName":"Yogurt 494","photoUrl":"","userId":"00985675351945098911"}},"colab":{"base_uri":"https://localhost:8080/","height":441}},"source":["\n","import numpy as np\n","\n","class ConvolutionalLayer(tf.keras.Model):\n","  def _init_(self, kernel_size, filter):\n","    super(ConvolutionalLayer, self)._init_(name='')\n","    self.layer = tf.keras.layers.Conv3D(filters, kernel, strides=[1,1,1], padding='SAME', activation='relu')\n","    #self.output_units = output_units\n","  \n","  \n","  #def build(self, input_shape):\n","    #return layer  \n","  \n","  def call(self, input):\n","    return self.layer(input)\n"," \n","  #def create_convolutional_layer(input, num_input_channels_, conv_filter_size, num_filters):\n","\n","\n","features = {\n","    \n","    'x': np.full((60, 20, 20, 3), 0)\n","}\n","\n","input_layer = tf.reshape(features[\"x\"], [-1, 60, 20, 20, 3])\n","#Conv3d_1a_7x7\n","layer1 = ConvolutionalLayer(input_layer, 7, 32)\n","#MaxPool3d_2a_3x3\n","layer2= ConvolutionalLayer(layer1, 1, 64)\n","layer = tf.nn.max_pool3d(input = layer2, ksize = [1, 1, 3, 3, 1], strides = [1, 1, 2, 2, 1], padding='SAME')\n","#'Conv3d_2b_1x1'\n","#'Conv3d_2b_1x1'\n","layer3 = ConvolutionalLayer(layer2, 1, 64)\n","#'Conv3d_2c_3x3'\n","layer4 = ConvolutionalLayer(layer3, 3, 192)\n","#'MaxPool3d_3a_3x3'\n","layer5 = ConvolutionalLayer(layer4, 1, 64)\n","#layer = tf.nn.max_pool3d(value = layer, ksize = [1, 1, 3, 3, 1], strides = [1, 1, 2, 2, 1], padding='SAME')\n","#'MaxPool3d_4a_3x3'\n","#layer5 = ConvolutionalLayer(layer4, 1, 64)\n","#layer = tf.nn.max_pool3d(value = layer, ksize = [1, 1, 3, 3, 1], strides = [1, 1, 2, 2, 1], padding='SAME')\n"],"execution_count":66,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got <__main__.ConvolutionalLayer object at 0x7f8c5ffddef0>","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-72d0a846c55b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#MaxPool3d_2a_3x3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mConvolutionalLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#'Conv3d_2b_1x1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#'Conv3d_2b_1x1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool3d\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   3878\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3879\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3880\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   3881\u001b[0m \u001b[0;31m# pylint: enable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool3d\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5783\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5784\u001b[0m         \u001b[0;34m\"MaxPool3D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5785\u001b[0;31m                      padding=padding, data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5786\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5787\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    528\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m               raise TypeError(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    528\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                          as_ref=False):\n\u001b[1;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[1;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 246\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    283\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    285\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = g.create_op(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    560\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    561\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    563\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class '__main__.ConvolutionalLayer'> to Tensor. Contents: <__main__.ConvolutionalLayer object at 0x7f8c5ffddef0>. Consider casting elements to a supported type."]}]},{"cell_type":"code","metadata":{"id":"Vb7fWlOvpOcP","colab_type":"code","colab":{}},"source":["\"\"\"\n","end_point = 'Inc_1'\n","with tf.variable_scope(end_point):\n","    with tf.variable_scope('Branch_0'):\n","      branch_0 = tf.nn.conv3d(\n","      filters = 64,\n","      filter=[1, 1, 1],\n","      padding = \"same\",\n","      activation=tf.nn.relu)\n","      \n","    with tf.variable_scope('Branch_1'):\n","      branch_1 = tf.nn.conv3d(\n","      filters = 96,\n","      filter=[1, 1, 1],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","      branch_1 = tf.nn.conv3d(\n","      filters = 128,\n","      kernel_size=[3, 3, 3],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","      \n","    with tf.variable_scope('Branch_2'):\n","      branch_2 = tf.layer.conv3d(\n","      filters = 16,\n","      kernel_size=[1, 1, 1],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","      branch_2 = tf.nn.conv3d(\n","      filters = 32,\n","      kernel_size=[3, 3, 3],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","      \n","    with tf.variable_scope('Branch_3'):\n","      branch_3 = tf.nn.conv3d(\n","      filters = 32,#\n","      kernel_size=[1, 3, 3, 3, 1],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","      branch_3 = tf.nn.conv3d(\n","      filters = 32,\n","      kernel_size=[1,1,1],\n","      padding = \"same\",\n","      activation = tf.nn.relu)\n","    net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGAqq3EjJVbU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"61776f77-5c01-4e82-aade-aad18129f289","executionInfo":{"status":"error","timestamp":1564083204872,"user_tz":300,"elapsed":172,"user":{"displayName":"Yogurt 494","photoUrl":"","userId":"00985675351945098911"}}},"source":[""],"execution_count":29,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-c81708bbccad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Conv3d_1a_7x7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_covolutional_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#MaxPool3d_2a_3x3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcreate_covolutional_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_covolutional_layer' is not defined"]}]},{"cell_type":"code","metadata":{"id":"OKJTl_lymaRA","colab_type":"code","colab":{}},"source":[")end_point = 'Inc_2'\n","with tf.variable_scope(end_point):\n","    with tf.variable_scope('Branch_0'):\n","      branch_0 = tf.layer.conv3d(\n","      filters = 128,\n","      kernel_size=[1, 1, 1],\n","      padding = \"same\",\n","      activation=tf.nn.relu)\n","    with tf.variable_scope('Branch_1'):\n","      branch_1 = tf.layer.conv3d(\n","      filters = 128,\n","      kernel_size=[1, 1, 1],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","      branch_1 = tf.layer.conv3d(\n","      filters = 192,\n","      kernel_size=[3, 3, 3],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","    with tf.variable_scope('Branch_2'):\n","      branch_2 = tf.layer.conv3d(\n","      filters = 32,\n","      kernel_size=[1, 1, 1],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","      branch_2 = tf.layer.conv3d(\n","      filters = 96,\n","      kernel_size=[3, 3, 3],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","    with tf.variable_scope('Branch_3'):\n","      branch_3 = tf.layer.conv3d(\n","      filters = 32,#\n","      kernel_size=[1, 3, 3, 3, 1],\n","      padding = \"same\",\n","      activation= tf.nn.relu)\n","      branch_3 = tf.layer.conv3d(\n","      filters = 32,\n","      kernel_size=[1,1,1],\n","      padding = \"same\",\n","      activation = tf.nn.relu)\n","    net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ljkO8d8vwJy","colab_type":"code","colab":{}},"source":["#code directly from github- using as a template for below code cell - DO NOT RUN\n","\n","end_point = 'MaxPool3d_4a_3x3'\n","    net = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1], strides=[1, 2, 2, 2, 1],\n","                           padding=snt.SAME, name=end_point)\n","    end_points[end_point] = net\n","    if self._final_endpoint == end_point: return net, end_points\n","    \n","    \n"," end_point = 'Mixed_4b'\n","    with tf.variable_scope(end_point):\n","      with tf.variable_scope('Branch_0'):\n","        branch_0 = Unit3D(output_channels=192, kernel_shape=[1, 1, 1],\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n","      with tf.variable_scope('Branch_1'):\n","        branch_1 = Unit3D(output_channels=96, kernel_shape=[1, 1, 1],\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n","        branch_1 = Unit3D(output_channels=208, kernel_shape=[3, 3, 3],\n","                          name='Conv3d_0b_3x3')(branch_1,\n","                                                is_training=is_training)\n","      with tf.variable_scope('Branch_2'):\n","        branch_2 = Unit3D(output_channels=16, kernel_shape=[1, 1, 1],\n","                          name='Conv3d_0a_1x1')(net, is_training=is_training)\n","        branch_2 = Unit3D(output_channels=48, kernel_shape=[3, 3, 3],\n","                          name='Conv3d_0b_3x3')(branch_2,\n","                                                is_training=is_training)\n","      with tf.variable_scope('Branch_3'):\n","        branch_3 = tf.nn.max_pool3d(net, ksize=[1, 3, 3, 3, 1],\n","                                    strides=[1, 1, 1, 1, 1], padding=snt.SAME,\n","                                    name='MaxPool3d_0a_3x3')\n","        branch_3 = Unit3D(output_channels=64, kernel_shape=[1, 1, 1],\n","                          name='Conv3d_0b_1x1')(branch_3,\n","                                                is_training=is_training)\n","      net = tf.concat([branch_0, branch_1, branch_2, branch_3], 4)\n","    end_points[end_point] = net\n","    if self._final_endpoint == end_point: return net, end_points"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wszqmc-dAbuW","colab_type":"code","colab":{}},"source":["\"\"\"\n","maxpool1 = tf.layers.conv3d(\n","      inputs = pool3,#number4\n","      filters = 64,\n","      kernel_size=[1, 3, 3, 3, 1],\n","      padding=\"same\",\n","      activation=tf.nn.relu)\n","    pool5 = tf.layers.max_pooling3d(inputs=conv5, pool_size=[2, 2, 2], strides=[1, 1, 2, 2, 1], name='MaxPool3d_5')\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m1bDce1iC6eK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0kp-7uMWwGxN","colab_type":"code","colab":{}},"source":["\"\"\"\n","AttributeError: module 'tensorflow' has no attribute 'layer'\n","variable 'name' necessary\n","end_points array?"],"execution_count":0,"outputs":[]}]}